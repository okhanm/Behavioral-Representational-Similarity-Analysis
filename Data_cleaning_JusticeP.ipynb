{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224c7c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing and merging complete!\n",
      "Adjustment complete!\n",
      "Final data processing complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Root directory\n",
    "root_dir = r\"C:\\Users\\psiok\\Desktop\\Justice Project\\CN_DATA\"\n",
    "\n",
    "# List all directories inside the root directory\n",
    "subject_dirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "\n",
    "# Define the columns we're interested in\n",
    "selected_columns = [\n",
    "    \"label_shame\", \"shame_condition\",\n",
    "    \"label_wrongness\", \"wrongness_condition\",\n",
    "    \"label_devaluation\", \"devaluation_condition\",\n",
    "    \"label_time\", \"time_condition\",\n",
    "    \"finalVar\"\n",
    "]\n",
    "\n",
    "# Define a function to process the raw data from a CSV file\n",
    "def process_raw_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the required columns exist in the data\n",
    "    if not set(selected_columns).issubset(data.columns):\n",
    "        print(f\"Warning: Missing columns in {file_path}. Skipping this file.\")\n",
    "        return None\n",
    "    \n",
    "    extracted_data = data[selected_columns]\n",
    "    adjusted_data = extracted_data.iloc[6:].reset_index(drop=True)\n",
    "\n",
    "    # Extract rows based on labels\n",
    "    datasets = []\n",
    "    labels = [\"shame\", \"wrongness\", \"devaluation\", \"time\"]\n",
    "    for label in labels:\n",
    "        if f'label_{label}' in adjusted_data.columns:\n",
    "            rows = adjusted_data[adjusted_data[f'label_{label}'].notna()]\n",
    "            datasets.append(rows[[f'label_{label}', f'{label}_condition', 'finalVar']])\n",
    "    \n",
    "    # Merge the datasets horizontally\n",
    "    merged_data = pd.concat([df.reset_index(drop=True) for df in datasets], axis=1)\n",
    "    return merged_data\n",
    "\n",
    "# Define columns for each condition\n",
    "condition_columns = {\n",
    "    \"shame\": [\"label_shame\", \"shame_condition\", \"finalVar\"],\n",
    "    \"wrongness\": [\"label_wrongness\", \"wrongness_condition\", \"finalVar.1\"],\n",
    "    \"devaluation\": [\"label_devaluation\", \"devaluation_condition\", \"finalVar.2\"],\n",
    "    \"time\": [\"label_time\", \"time_condition\", \"finalVar.3\"]\n",
    "}\n",
    "\n",
    "# Function to extract and sort data based on a given condition\n",
    "def extract_and_sort(data, columns):\n",
    "    # Extract the columns\n",
    "    extracted_data = data[columns]\n",
    "    \n",
    "    # Drop rows where the label is NaN\n",
    "    extracted_data = extracted_data[extracted_data[columns[0]].notna()]\n",
    "    \n",
    "    # Sort by the label\n",
    "    sorted_data = extracted_data.sort_values(by=[columns[0]])\n",
    "    \n",
    "    return sorted_data\n",
    "\n",
    "# Function to merge the finalVar columns while preserving NaN values\n",
    "def merge_finalVars(row):\n",
    "    for val in row:\n",
    "        if not pd.isna(val):\n",
    "            return val\n",
    "    return None  # If all values are NaN, return None\n",
    "\n",
    "# Process raw data, merge, and save the processed data\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_path = os.path.join(root_dir, subject_dir)\n",
    "    \n",
    "    # Process each raw CSV file\n",
    "    processed_data_list = []\n",
    "    raw_csv_files = [f for f in os.listdir(subject_path) if f.endswith('.csv') and not f.startswith('processed_')]\n",
    "    for raw_csv_file in raw_csv_files:\n",
    "        raw_csv_path = os.path.join(subject_path, raw_csv_file)\n",
    "        processed_data = process_raw_data(raw_csv_path)\n",
    "        if processed_data is not None:\n",
    "            processed_data_list.append(processed_data)\n",
    "    \n",
    "    # Merge the processed data\n",
    "    if processed_data_list:\n",
    "        merged_data = pd.concat(processed_data_list, axis=0, ignore_index=True)\n",
    "        merged_file_name = f\"merged_{subject_dir}.csv\"\n",
    "        merged_file_path = os.path.join(subject_path, merged_file_name)\n",
    "        merged_data.to_csv(merged_file_path, index=False)\n",
    "\n",
    "print(\"Processing and merging complete!\")\n",
    "\n",
    "# Adjust the merged data and save the adjusted data\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_path = os.path.join(root_dir, subject_dir)\n",
    "    merged_file_name = f\"merged_{subject_dir}.csv\"\n",
    "    merged_file_path = os.path.join(subject_path, merged_file_name)\n",
    "    \n",
    "    if os.path.exists(merged_file_path):\n",
    "        data = pd.read_csv(merged_file_path)\n",
    "        adjusted_data_list = [extract_and_sort(data, columns) for _, columns in condition_columns.items()]\n",
    "        adjusted_data = pd.concat(adjusted_data_list, axis=0).reset_index(drop=True)\n",
    "        adjusted_file_name = f\"adjusted_{subject_dir}.csv\"\n",
    "        adjusted_file_path = os.path.join(subject_path, adjusted_file_name)\n",
    "        adjusted_data.to_csv(adjusted_file_path, index=False)\n",
    "\n",
    "print(\"Adjustment complete!\")\n",
    "\n",
    "# Load the adjusted data, concatenate columns, and save the final data\n",
    "for subject_dir in subject_dirs:\n",
    "    subject_path = os.path.join(root_dir, subject_dir)\n",
    "    adjusted_file_name = f\"adjusted_{subject_dir}.csv\"\n",
    "    adjusted_file_path = os.path.join(subject_path, adjusted_file_name)\n",
    "    \n",
    "    if os.path.exists(adjusted_file_path):\n",
    "        data = pd.read_csv(adjusted_file_path)\n",
    "        labels = data[['label_shame', 'label_wrongness', 'label_devaluation', 'label_time']].fillna('').sum(axis=1)\n",
    "        conditions = data[['shame_condition', 'wrongness_condition', 'devaluation_condition', 'time_condition']].fillna('').sum(axis=1)\n",
    "        finalVars = data[['finalVar', 'finalVar.1', 'finalVar.2', 'finalVar.3']].apply(merge_finalVars, axis=1)\n",
    "        \n",
    "        final_data = pd.DataFrame({\n",
    "            'label': labels,\n",
    "            'condition': conditions,\n",
    "            'finalVar': finalVars\n",
    "        })\n",
    "        \n",
    "        final_data = final_data.sort_values(by='label')\n",
    "        \n",
    "        final_file_name = f\"final_{subject_dir}.csv\"\n",
    "        final_file_path = os.path.join(subject_path, final_file_name)\n",
    "        final_data.to_csv(final_file_path, index=False)\n",
    "\n",
    "print(\"Final data processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561dfe07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
